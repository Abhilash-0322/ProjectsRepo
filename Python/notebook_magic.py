# -*- coding: utf-8 -*-
"""notebook_magic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tools/notebook_magic.ipynb

##### Copyright 2023 Google LLC.
"""

#@title Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""# PaLM Colab Magic

This notebook introduces Colab magic commands for PaLM. Magics make it easy to develop, test, compare, and evaluate prompts from within a Colab notebook.

<table class="tfo-notebook-buttons" align="left">
  <td>
    <a target="_blank" href="https://developers.generativeai.google/tools/notebook_magic"><img src="https://developers.generativeai.google/static/site-assets/images/docs/notebook-site-button.png" height="32" width="32" />View on Generative AI</a>
  </td>
  <td>
    <a target="_blank" href="https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tools/notebook_magic.ipynb"><img src="https://www.tensorflow.org/images/colab_logo_32px.png" />Run in Google Colab</a>
  </td>
  <td>
    <a target="_blank" href="https://github.com/google/generative-ai-docs/blob/main/site/en/tools/notebook_magic.ipynb"><img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" />View source on GitHub</a>
  </td>
</table>

## Setup

Follow the steps below to install and test the magics.

### Installing the PaLM magic
To use the PaLM magic commands in Colab or other IPython environment, you will first need to download and install the [`google-generativeai`](https://pypi.org/project/google-generativeai) Python package.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install -q google-generativeai

"""### Loading the PaLM magic

Next, load the `%%palm` magic by using the `%load_ext` magic:
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext google.generativeai.notebook

"""### Test the installation
To test for correct installation of the magic commands, run `%%palm --help`. Note that you will also need a PaLM API key, if you don't have one already (see next step).
"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm --help

"""### Getting a PaLM API key

To use the PaLM API, you will need to [create an API key](https://developers.generativeai.google/tutorials/setup). (You only need to do this step once.)

### Set the API key in the notebook

Set your API key by running the cell below.

Caution: The API key is a secret that grants access to the API from your account so make sure to remove it from the notebook before saving, and do not share any notebooks that contain API keys.
"""

# Commented out IPython magic to ensure Python compatibility.
# %env GOOGLE_API_KEY=YOUR PALM KEY

"""## PaLM magic commands: `run`, `compile`, `compare`, and `evaluate`

PaLM magics provide four different commands:
1. `run`
1. `compile`
1. `compare`
1. `evaluate`

### Command: `palm run`

The `run` command sends the contents of the cell to the model.

Because running prompts is so common, PaLM magics defaults to the `run` command if no command is given. For example, the next two cells are identical.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm run
# The opposite of hot is

# Commented out IPython magic to ensure Python compatibility.
# %%palm
# The opposite of hot is

"""#### Understanding the output

The `Prompt` column shows the text that was sent to the model, and the `text_result` column shows the result. The other columns will be introduced as you progress through this guide.

### Prompt templates

Prompts do not have to be fixed strings. You can inject values into a prompt using template placeholders by using `{curly braces}`.
"""

english_words = {
    # Each value here (hot, cold) will be substituted in for {word} in the prompt
    'word': ['hot', 'cold']
}

# Commented out IPython magic to ensure Python compatibility.
# %%palm --inputs english_words
# The opposite of {word} is

"""#### Understanding the output

The `Input Num` column tracks the index of the input word in the list(s). In
these examples, `Input Num` of `0` is `'hot'`, and `1` is `'cold'`.

#### Specifying multiple sets of inputs

You can also specify multiple sets of inputs at one time.
"""

extreme_temperatures = {
    'word': ['hot', 'cold']
}
minor_temperatures = {
    'word': ['warm', 'chilly']
}

# Commented out IPython magic to ensure Python compatibility.
# %%palm --inputs extreme_temperatures minor_temperatures
# The opposite of {word} is

"""### Reading data from Google Sheets

The PaLM magic can also read and write to Google Sheets. You will need to be logged in to access Sheets data. This section focuses on reading data from Sheets; a [later section](#sheets_output) shows how you can write output to a Google Sheet.

#### Log in and authorize access to Sheets
"""

#@title
from google.colab import auth
auth.authenticate_user()

import google.auth
creds, _ = google.auth.default()

from google.generativeai.notebook import magics
magics.authorize(creds)

"""#### Formatting a spreadsheet for use with the PaLM magic

Pass the ID or URL of a Google Sheet to the `--sheets_input_names` flag to load it up as template data.

Use the following format in your spreadsheet to use the data in a prompt template:
1. Put the names of the variables (of your prompt template) in the first row of the sheet.
1. Put the data to substitute for each variable in the rows below.

For example, if your prompt template has two variables to substitute, `name` and `temperament`, you would write your spreadsheet like this:

|name|temperament|
-----|-----------
|Milo|cheeky|
|Bigsly|relaxed|
|Subra|shy|

"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm --sheets_input_names https://docs.google.com/spreadsheets/d/1UHfpkmBqIX5RjeJcGXOevIEhMmEoKlf5f9teqwQyHqc/edit
# Create a single sentence description of a monkey's personality. The monkey's name is {name} and it has a {temperament} temperament.

"""#### Try it yourself!

To try this out using your own data, create a [new Sheet](http://sheet.new/) and pass the ID to `--sheets_input_names`. As well as ID and URL, you can also search your sheets by title, e.g. `%%palm --sheets_input_names "Animal adjectives"`.

#### Combining Sheets inputs with Python inputs

Sheets inputs can also be combined with `--inputs`:
"""

new_monkeys = {
    'name': ['Hackerella'],
    'temperament': ['clever'],
}

# Commented out IPython magic to ensure Python compatibility.
# %%palm --inputs new_monkeys --sheets_input_names 1UHfpkmBqIX5RjeJcGXOevIEhMmEoKlf5f9teqwQyHqc 1UHfpkmBqIX5RjeJcGXOevIEhMmEoKlf5f9teqwQyHqc
# Create a single sentence description of a monkey's personality. The monkey's name is {name} and it has a {temperament} temperament.

"""### Command: `palm eval`

Use `%%palm eval` to compare the output of a prompt with known ground-truth data.
"""

test_data = {
    "word": ["dog", "cat", "house"]
}
ground_truth = ["chien", "chat", "maison"]

# Commented out IPython magic to ensure Python compatibility.
# %%palm eval --inputs test_data --ground_truth ground_truth
# English: Hello
# French: Bonjour
# English: {word}
# French:

"""#### Post processing model outputs

To perform ground-truth testing, you may need to post-process the model output.

[Post-processing](#post_processing) functions allow you to define a function that processes the model output. In the case of the `eval` command, only the result column is used in the final equality check.

Use the `post_process_replace_fn` decorator to define a function to post-process results:
"""

from google.generativeai.notebook import magics

# Define a function to extract only the first response.
@magics.post_process_replace_fn
def extract_and_normalize(input):
  first_line, *unused = input.split('English:')
  return first_line.strip().lower()

"""The `extract_and_normalize` function defined above will take the output from the model and trim any repeated language pairs, leaving just the first response. Check out the [post-processing](#post_processing) section to learn more about post-processing."""

# Commented out IPython magic to ensure Python compatibility.
# %%palm eval --inputs test_data --ground_truth ground_truth | extract_and_normalize
# English: Hello
# French: Bonjour
# English: {word}
# French:

"""### Command: `palm compile`

Use the `%%palm compile` command to convert a prompt with placeholders to a  function callable from within Python.

All flags and post-processing are "compiled" into the function and will be used when invoked.

In this example, a function called `translate_en_to_fr` is created, using the `extract_and_normalize` post-processing function from [before](#palm_eval).
"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm compile translate_en_to_fr | extract_and_normalize
# English: Hello
# French: Bonjour
# English: {word}
# French:

en_words = ['cat', 'dog']
translate_en_to_fr({'word': en_words})

"""#### Output formats

By default, a "compiled" function returns its output as an object that will be displayed as Pandas `DataFrame`. However, you can convert the results object to a `DataFrame` or dictionary with `.as_dict()` or `.as_dataframe()`, respectively.

For more information, see the [`--outputs`](#python_output) flag.
"""

results = translate_en_to_fr({'word': en_words}).as_dict()

fr_words = results['text_result']

for en, fr in zip(en_words, fr_words):
  print(f'{fr} is French for {en}')

"""### Command: `palm compare`

`%%palm compare` runs compiled prompts and produces a table with the comparison results side-by-side, so you can inspect the differences.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm compile few_shot_prompt
# English: Hello
# French: Bonjour
# English: {word}
# French:

# Commented out IPython magic to ensure Python compatibility.
# %%palm compile zero_shot_prompt
# {word} translated to French is:

words = {
    "word": ["dog", "cat", "house"]
}

# Commented out IPython magic to ensure Python compatibility.
# %%palm compare few_shot_prompt zero_shot_prompt --inputs words

"""#### Custom comparison functions

By default, `compare` just checks for equalilty in the returned results. However, you can specify one or more custom functions with the `--compare_fn` flag:.
"""

def average_word_length(lhs, rhs):
  """Count the average number of words used across prompts."""
  return (len(lhs.split(' ')) + len(rhs.split(' '))) / 2

def shortest_answer(lhs, rhs):
  """Label the prompt that generated the shortest output."""
  if len(lhs) < len(rhs):
    return 'first'
  elif len(lhs) > len(rhs):
    return 'second'
  else:
    return 'same'

# Commented out IPython magic to ensure Python compatibility.
# %%palm compare few_shot_prompt zero_shot_prompt --inputs words --compare_fn average_word_length shortest_answer

"""## Other commands

### Help

The `--help` flag displays the supported commands that you can pass directly to `%%palm`

Append `--help` to view detailed documentation for each command. For example,
"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm run --help

"""### Models

Use the `--model` flag to specify the PaLM model variant you wish to use.

See the [`list_models()`](/api/python/google/generativeai/list_models) method to retrieve the supported models. The PaLM magic can be used with any model supporting the `generateText` method.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm run --model models/text-bison-001
# My favourite color is

"""#### Model parameters

You can also configure model parameters, such as [`--candidate_count`](#candidate_count) and `--temperature`.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm run --model models/text-bison-001 --temperature 0.5
# My favourite color is

"""### Debugging: The echo model

An `echo` model is also available that will echo the prompt back to you. It does not make any API calls or consume your quota so it can be a fast and simple way to test output or post-processing.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm --model_type echo
# A duck's quack does not echo.

"""### Export output to Python {:#python_output}

In addition to displaying tabular output, the PaLM magic can save model output to Python variables, allowing you to manipulate them further or to export your results.

In this example, the output is saved to a Python variable: `fave_colors`

"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm --outputs fave_colors
# The best colors to wear in spring-time are

"""Output variables are custom objects that will display as Pandas `DataFrame`s by default. They can be coerced into a Python dictionary or dataframe explicitly by calling `as_dict()` or `as_pandas_dataframe()`."""

from pprint import pprint

pprint(fave_colors.as_dict())

"""### Write to Google Sheets {:#sheets_output}

You can save output back to Google Sheets, using `--sheets_output_names`. You must be logged in, and you must have the appropriate permissions to access private Sheets.

To try this out, create a [new Sheet](http://sheet.new/) and name it `Translation results`. Like the input flag, the `--sheets_output_names` flag also accepts the sheet URL or ID in place of the textual name.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm --inputs english_words --sheets_output_names "Translation results"
# English: Hello
# French: Bonjour
# English: {word}
# French:

"""The results are saved to a new tab and contain the same data you see here in Colab.

![Example of a saved sheet](https://developers.generativeai.google/tools/sheets_output.png)

### Generating multiple candidates {:#candidate_count}

To generate more than one output for a single prompt, you can pass `--candidate_count` to the model. This is set to 1 by default, which outputs only the top result.

Sometimes the model will generate the same output across candidates. These can be filtered with the `--unique` flag, which de-duplicates results out of the candidate batch (but not across multiple prompts).
"""

# Commented out IPython magic to ensure Python compatibility.
# %%palm run --temperature 1.0 --candidate_count 8 --unique
# In a single word, my favourite color is

"""The `Result Num` column distinguishes multiple candidates generated from the same prompt.

### Post-processing model output {:#post_processing}

The broad range of possible outputs and structures can make it difficult to adapt the model's output to your problem domain. The PaLM magic provides post-processing options that allow you to modify or process model output using Python code.

Post-processing functions can either add a new column to the output, or modify the `text_result` column. The `text_result` column is the last column, and is used by the `eval` and `compare` commands to determine the final output.

Here are some sample functions to use in post-processing. One adds a new column and the other updates the result column, using the `post_process_replace_fn` decorator.
"""

import re
from google.generativeai.notebook import magics

# Add a new column.
def word_count(result):
  return len(result.split(' '))

# Modify the text_result column
@magics.post_process_replace_fn
def extract_first_sentence(result):
  """Extracts the first word from the raw result."""
  first, *_ = re.split(r'\.\s*', result)
  return first

"""To use these functions, append them to the `%%palm` command using the pipe (`|`) operator, like so."""

# Commented out IPython magic to ensure Python compatibility.
# %%palm run | word_count | extract_first_sentence
# The happiest thing I can imagine is

"""Order matters here. When `word_count` is invoked, the original model output is used to calculate the number of words. If you swap these around, the word count would instead be the number of words in the extracted first sentence.

## Further reading

* Refer to the [LLMs concepts guide](https://developers.generativeai.google/guide/concepts) to learn more about LLMs.
* Check out the [prompt guidelines](https://developers.generativeai.google/guide/prompt_best_practices) to learn more about crafting prompts to get the most out of working with PaLM.
* To prototype and experiment with different prompts, check out [MakerSuite](https://makersuite.google.com/). Also, refer to the [MakerSuite quickstart](https://developers.generativeai.google/tutorials/makersuite_quickstart) for more information.
"""